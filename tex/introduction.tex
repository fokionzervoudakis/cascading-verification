\section{Introduction}

\noindent Model checking is an established formal verification method whereby a model checker systematically explores the state space of a system model to verify that each state satisfies a set of desired behavioral properties~\cite{Baier_2008}.

Research in model checking has focused on enhancing the efficiency and scalability of verification by employing partial order reduction, and by exploiting symmetries and other state space properties. This research is important because it mitigates the complexity of model checking algorithms, thereby enabling model builders to verify larger, more elaborate models. But the complexity associated with model and property specification has yet to be sufficiently addressed. Popular model checkers tend to support low-level modeling languages that require intricate models to represent even the simplest systems. For example, PROMELA, the modeling language used by the model checker Spin, is essentially a dialect of the relatively low-level programming language~C\@. Due to lack of appropriate control structures, the modeling language used by the probabilistic model checker PRISM forces model builders to pollute model components with variables that act as counters. These variables are manipulated at runtime to achieve desirable control flow from otherwise unordered commands.

Modeling complexity arises in part from the need to encode \emph{domain knowledge}---including domain objects and concepts, and their relationships---at relatively low levels of abstraction. We will demonstrate that, once formalized, domain knowledge can be reused to enhance the abstraction level of model and property specifications, and the effectiveness of probabilistic model checking.

Leveraged appropriately, formal domain knowledge can decrease specification and verification costs. On the verification side, the model checking framework Bogor achieves significant state space reductions in model checking of program code by exploiting characteristics of the program code's deployment platform~\cite{Robby_2003}. On the specification side, \emph{semantic model checking} supplements model checking with semantic reasoning over domain knowledge encoded in the \emph{Web Ontology Language} (OWL). Semantic model checking has been used to verify Web services~\cite{Narayanan_2002,Di_Pietro_2012}; Web service security requirements~\cite{Boaro_2010}; probabilistic Web services~\cite{Oghabi_2011}; Web service interaction protocols~\cite{Ankolekar_2005}; and Web service flow~\cite{Liu_2008}. Additionally, multi-agent model checking has been used to verify OWL-S process models~\cite{Lomuscio_2009}.

OWL is a powerful knowledge representation formalism, but expressive and reasoning limitations constrain its utility in the context of semantic model checking; for example, OWL cannot reason about triangular or self-referential relationships. As a W3C-approved OWL extension, the Semantic Web Rule Language (SWRL) addresses some of these limitations by integrating OWL with Horn-like rules. But OWL+SWRL cannot reason effectively with negation. The \emph{logic programming} (LP) language Prolog can be used to overcome problems that are intractable in OWL+SWRL\@. Prolog, however, lacks several of the expressive features afforded by OWL including support for equivalence and disjointness.

This paper describes a novel method for domain-specific model checking called \emph{cascading verification}. Our method uses composite reasoning over high-level system specifications and formalized domain knowledge to synthesize \emph{both} low-level system models and the behavioral properties that need to be verified with respect to those models. In particular, model builders use a high-level \emph{domain-specific language} (DSL) to encode system specifications that can be analyzed with model checking. A \emph{compiler} uses automated reasoning to verify the consistency between each specification and domain knowledge encoded in OWL+SWRL and Prolog, which are combined to overcome their individual limitations. If consistency is deduced, then explicit and inferred domain knowledge is used by the compiler to synthesize a \emph{discrete-time Markov chain} (DTMC) model and \emph{probabilistic computation tree logic} (PCTL) properties from template code. PRISM subsequently verifies the model against the properties. Thus, verification \emph{cascades} through several stages of reasoning and analysis.

Our method gains significant functionality from each of its constituent technologies. OWL supports expressive knowledge representation and efficient reasoning; SWRL extends OWL with Horn-like rules that can model complex relational structures and self-referential relationships; Prolog extends OWL+SWRL with the ability to reason effectively with negation; DTMC introduces the ability to formalize probabilistic behavior; and PCTL supports the elegant expression of probabilistic properties.

Cascading verification is illustrated with a prototype system that verifies the correctness of \emph{uninhabited aerial vehicle} (UAV) missions. We use the prototype to analyze~58 mission plans, which are based on real-world mission scenarios developed independently by the Defense Advanced Research Projects Agency (DARPA)~\cite{DARPA} and the Defence Research and Development Canada (DRDC) agency~\cite{Youngson_2004}. UAVs are contextualized by a particularly interesting and important experimental domain. The stochastic nature of UAV missions led us to select \emph{probabilistic model checking}, and in particular the popular tool PRISM~\cite{Hinton_2006}, for the verification of UAV mission plans.

This paper presents three research contributions. First, we describe a novel model checking method that leverages domain knowledge to realize a non-trivial reduction in the effort required to specify system models and behavioral properties. For example, from 23 lines of YAML code comprising 92 tokens, cascading verification synthesizes 104 lines of PRISM code comprising 744 tokens and three behavioral properties (with our prototype, model builders encode mission specifications in a domain-specific dialect of the human-readable YAML format~\cite{Evans}).

Second, we describe a composite inference mechanism that supports the synthesis of system models and their desired behavioral properties for probabilistic model checking. Third, we present a prototype system that uses our method to verify UAV mission plans, thereby demonstrating the utility of cascading verification in the context of a significant application domain.

The remainder of this paper is structured as follows. Section~\ref{sec:Background} presents background material on the technologies that constitute cascading verification, and on the UAV domain. Section~\ref{sec:Method_Overview} presents an overview of cascading verification, and an example UAV mission that underpins subsequent discussion and examples. Section~\ref{sec:Domain_Modeling} describes how domain knowledge is encoded in OWL+SWRL, Prolog, and DTMC and PCTL templates. Our prototype implementation of cascading verification is described in Section~\ref{sec:Cascading_Verification}. An evaluation, which considers the portability of our method, and related work are presented in Section~\ref{sec:Evaluation} and Section~\ref{sec:Related_Work}, respectively. Section~\ref{sec:Conclusions_and_Future_Work} concludes the paper and discusses future work.
